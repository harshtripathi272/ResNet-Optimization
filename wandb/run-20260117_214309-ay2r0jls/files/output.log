Initializing PerforatedAI...
Applying strict dendrite targeting...
  -> Targeted: layer3.0.conv2
  -> Targeted: layer3.1.conv2
  -> Targeted: layer4.0.conv2
Configuring PAI settings...
New list value of "_modules_to_track": [<class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.linear.Linear'>, <class 'torch.nn.modules.batchnorm.BatchNorm2d'>]
Running a test of Dendrite Capacity.
Perforated Backpropagation ENABLED (Paid License Active)
/home/pranshu/miniconda3/envs/perforated-nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Adding validation score 54.17000000
Checking PAI switch with mode n, switch mode DOING_SWITCH_EVERY_TIME, epoch 0, last improved epoch 0, total epochs 0, n: 6, num_cycles: 0
Returning True - switching every time
Importing best Model for switch to PA...
Epoch 1: Model Restructured! Adding Dendrite.
Traceback (most recent call last):
  File "/data3/Pranshu/elephant_detection/PyTorch/CIFAR-100/dendritic_experiment/main.py", line 83, in <module>
    main()
  File "/data3/Pranshu/elephant_detection/PyTorch/CIFAR-100/dendritic_experiment/main.py", line 65, in main
    acc_pai, params_pai = train.run_experiment(model_pai, "ResNet18_PAI",
  File "/data3/Pranshu/elephant_detection/PyTorch/CIFAR-100/dendritic_experiment/train.py", line 221, in run_experiment
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.NUM_EPOCHS, last_epoch=epoch)
  File "/home/pranshu/miniconda3/envs/perforated-nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 1085, in __init__
    super().__init__(optimizer, last_epoch)
  File "/home/pranshu/miniconda3/envs/perforated-nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 108, in __init__
    raise KeyError(
KeyError: "param 'initial_lr' is not specified in param_groups[0] when resuming an optimizer"
Traceback (most recent call last):
  File "/data3/Pranshu/elephant_detection/PyTorch/CIFAR-100/dendritic_experiment/main.py", line 83, in <module>
    main()
  File "/data3/Pranshu/elephant_detection/PyTorch/CIFAR-100/dendritic_experiment/main.py", line 65, in main
    acc_pai, params_pai = train.run_experiment(model_pai, "ResNet18_PAI",
  File "/data3/Pranshu/elephant_detection/PyTorch/CIFAR-100/dendritic_experiment/train.py", line 221, in run_experiment
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.NUM_EPOCHS, last_epoch=epoch)
  File "/home/pranshu/miniconda3/envs/perforated-nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 1085, in __init__
    super().__init__(optimizer, last_epoch)
  File "/home/pranshu/miniconda3/envs/perforated-nlp/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 108, in __init__
    raise KeyError(
KeyError: "param 'initial_lr' is not specified in param_groups[0] when resuming an optimizer"
